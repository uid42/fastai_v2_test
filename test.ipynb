{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "#from FLAI.detect_symbol.exp import databunch as databunch_detsym\n",
    "from FLAI.detect_symbol.exp import resnet_ssd as resnet_ssd_detsym\n",
    "from FLAI.detect_symbol.exp import anchors_loss_metrics as anchors_loss_metrics_detsym\n",
    "from FLAI.detect_symbol.exp import optimizer as optimizer_detsym\n",
    "#from FLAI.detect_symbol.exp import init_model as init_model_detsym\n",
    "#from FLAI.detect_symbol.exp import tensorboard_callback\n",
    "#from FLAI.detect_symbol.exp import scheduling_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最后会引用detect_symbol.databunch，ImageList找不到\n",
    "# sys.path.append('../sick_tree_detection')\n",
    "# from sick_tree_detection.exp import anchors_loss_metrics as anchors_loss_metrics_sicktree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 应对无目标的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_pad_intlbl(samples, pad_idx=0):\n",
    "    \"Function that collect `samples` of labelled bboxes and adds padding with `pad_idx`.\"\n",
    "    samples = [(s[0], *clip_remove_empty(*s[1:])) for s in samples]\n",
    "    max_len = max([len(s[2]) for s in samples])\n",
    "    def _f(img,bbox,lbl):\n",
    "        bbox = torch.cat([bbox,bbox.new_zeros(max_len-bbox.shape[0], 4)])\n",
    "        #lbl  = torch.cat([lbl, lbl .new_zeros(max_len-lbl .shape[0], int)+pad_idx])\n",
    "        #在无目标也就是lbl为[]的情况下，lbl  = torch.cat([lbl, lbl .new_zeros(max_len-lbl .shape[0])+pad_idx])\n",
    "        #上面的代码即使指定了dtype=torch.int得到的仍然是浮点数。会导致后面的报错不是索引\n",
    "        if lbl.shape[0] != 0:\n",
    "            lbl  = torch.cat([lbl, lbl .new_zeros(max_len-lbl .shape[0])+pad_idx])\n",
    "        else:\n",
    "            lbl = lbl.new_zeros(max_len, dtype = torch.int) + pad_idx\n",
    "\n",
    "        \n",
    "        return img,bbox,lbl\n",
    "    return [_f(*s) for s in samples]\n",
    "\n",
    "BBoxBlock = TransformBlock(type_tfms=TensorBBox.create, item_tfms=PointScaler, dls_kwargs = {'before_batch': bb_pad_intlbl})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取BBox和label  \n",
    "两个是分开进行的。并且BBox的顺序改成了先x后y，使用v1版的fastai的数据集的时候需要转换顺序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "pat_coord = re.compile(r'\\d+')\n",
    "pat_clas = re.compile(r'\\w+')\n",
    "pat_imgName = re.compile(r'(\\w+/\\d+\\.png)$')\n",
    "pat_imgName = re.compile(r'(\\w+/\\d+\\.jpg)$')\n",
    "def get_label_from_df(fn, df, pat_imgName, box_col, cat_col):    \n",
    "    fn = str(fn)\n",
    "    pat_cat = re.compile(r'\\w+')\n",
    "    \n",
    "    fn = pat_imgName.findall(str(fn))[0]\n",
    "    cats = df.loc[fn,cat_col]\n",
    "    cats = pat_clas.findall(cats)\n",
    "    \n",
    "    return cats\n",
    "\n",
    "def get_boxes_from_df(fn, df, pat_imgName, box_col, cat_col):\n",
    "    fn = str(fn)\n",
    "    pat_num = re.compile(r'\\d+')\n",
    "    pat_cat = re.compile(r'\\w+')\n",
    "    fn = pat_imgName.findall(str(fn))[0]\n",
    "    #print('dbg1', fn)\n",
    "    \n",
    "    boxes = df.loc[fn,box_col]\n",
    "    boxes = pat_num.findall(boxes)\n",
    "    #boxes = list(map(np.long, boxes))\n",
    "    boxes = list(map(np.int32, boxes))\n",
    "    boxes = np.array(boxes).reshape(-1,4)\n",
    "    \n",
    "    #fastai2里面bbox的顺序改成了xy的顺序。现在用的这个数据集还是v1里面的yx的顺序。这里调整一下\n",
    "    boxes = boxes[...,[1, 0, 3, 2]]\n",
    "    boxes = boxes.tolist()\n",
    "    \n",
    "    cats = df.loc[fn,cat_col]\n",
    "    cats = pat_clas.findall(cats)\n",
    "    #print('dbg2', fn, boxes, cats)\n",
    "    assert len(boxes)==len(cats), 'length of bounding boxes and categories not equeal.'\n",
    "    \n",
    "    #print('dbg_boxes:', boxes)    \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成DataBlock\n",
    "作用相当于之前的DataBunch  \n",
    "item_tfms=Resize(128) 作用类似v1里面的after_open，可以对图片进行一些处理，但是这个处理无法作用在y上,如果需要改变图片尺寸连带y一起改变，应该在aug_transforms里面指定size参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_db():\n",
    "    get_y1 = partial(get_boxes_from_df, df=df, pat_imgName=pat_imgName, box_col='box', cat_col='cls')\n",
    "    get_y2 = partial(get_label_from_df, df=df, pat_imgName=pat_imgName, box_col='box', cat_col='cls')\n",
    "    \n",
    "    syms = DataBlock(blocks=(ImageBlock, BBoxBlock, BBoxLblBlock),\n",
    "                     get_items=get_image_files,\n",
    "                     splitter=RandomSplitter(),\n",
    "                     get_y=[get_y1, get_y2],\n",
    "                     #item_tfms=Resize(128),\n",
    "                     #batch_tfms=aug_transforms(size=(128,128)),\n",
    "                     n_inp=1)\n",
    "    return syms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = '/home/dev/jupyter/detect_symbol/data/ds_20200429/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = src_path + 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(src_path + 'gends.csv',index_col=0)\n",
    "df = df.set_index('image')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syms = get_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在docker中如果没有设置-shm-size，不设置num_workers=0会使用_MultiProcessingDataLoaderIter，导致错误： \n",
    "Unable to write to file </torch_18692_1954506624>\n",
    "https://discuss.pytorch.org/t/unable-to-write-to-file-torch-18692-1954506624/9990\n",
    "\n",
    "在fastai v1中对应的错误是内存溢出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dls = syms.dataloaders(path, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dls.show_batch(max_n = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#syms.summary(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dts = syms.datasets(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc['images/02364.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型和训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_ssd_detsym.get_resnet34_1ssd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvs,_,_,avs,_,_ = anchors_loss_metrics_detsym.get_ga666()\n",
    "gaf = anchors_loss_metrics_detsym.GridAnchor_Funcs(gvs,avs,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(anchors_loss_metrics_detsym.yolo_L, gaf=gaf, conf_th=1, clas_weights=None, lambda_nconf=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = cnn_learner(dls, model, pretrained=False)\n",
    "learn = Learner(dls, model, loss_func = loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.60% [2/125 01:05<1:06:49 7.1698]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dbg():\n",
    "    import pdb;pdb.set_trace()\n",
    "    #dls.show_batch()\n",
    "    #dls = syms.dataloaders(path)\n",
    "    syms2 = DataBlock(blocks=(ImageBlock, BBoxBlock, BBoxLblBlock),\n",
    "                 get_items=get_image_files,\n",
    "                 splitter=RandomSplitter(),\n",
    "                 get_y=[get_y1, get_y2],\n",
    "                 item_tfms=Resize(128),\n",
    "                 #batch_tfms=aug_transforms(),\n",
    "                 n_inp=1)\n",
    "    dls = syms2.dataloaders(path)\n",
    "    dls.show_batch()\n",
    "dbg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_source = untar_data(URLs.COCO_TINY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, lbl_bbox = get_annotations(coco_source/'train.json')\n",
    "img2bbox = dict(zip(images, lbl_bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y1(o):\n",
    "    #print('dbg0', o)\n",
    "    #return [img2bbox[o.name][0], img2bbox[o.name][1]]\n",
    "    return img2bbox[o.name][0]\n",
    "\n",
    "def get_y2(o): \n",
    "    return img2bbox[o.name][1]\n",
    "\n",
    "coco = DataBlock(blocks=(ImageBlock, BBoxBlock, BBoxLblBlock),\n",
    "                 get_items=get_image_files,\n",
    "                 splitter=RandomSplitter(),\n",
    "                 get_y=[get_y1, get_y2], #[lambda o: img2bbox[o.name][0], lambda o: img2bbox[o.name][1]]\n",
    "                 item_tfms=Resize(128),\n",
    "                 batch_tfms=aug_transforms(),\n",
    "                 n_inp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocodls = coco.dataloaders('/root/.fastai/data/coco_tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cocodls.show_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "#                  get_items=get_image_files, \n",
    "#                  splitter=RandomSplitter(seed=42),\n",
    "#                  get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
    "#                  item_tfms=Resize(460),\n",
    "#                  batch_tfms=aug_transforms(size=224, min_scale=0.75))\n",
    "# dls = pets.dataloaders(path/\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
