{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.progress import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.tensorboard import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "#from FLAI.detect_symbol.exp import databunch as databunch_detsym\n",
    "from FLAI.detect_symbol.exp import resnet_ssd as resnet_ssd_detsym\n",
    "from FLAI.detect_symbol.exp import anchors_loss_metrics as anchors_loss_metrics_detsym\n",
    "from FLAI.detect_symbol.exp import optimizer as optimizer_detsym\n",
    "#from FLAI.detect_symbol.exp import init_model as init_model_detsym\n",
    "#from FLAI.detect_symbol.exp import tensorboard_callback\n",
    "#from FLAI.detect_symbol.exp import scheduling_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../sick_tree_detection')\n",
    "from exp import anchors_loss_metrics as anchors_loss_metrics_sicktree\n",
    "from exp import resnet_ssd as resnet_ssd_sicktree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 应对无目标的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_pad_intlbl(samples, pad_idx=0):\n",
    "    \"Function that collect `samples` of labelled bboxes and adds padding with `pad_idx`.\"\n",
    "    samples = [(s[0], *clip_remove_empty(*s[1:])) for s in samples]\n",
    "    max_len = max([len(s[2]) for s in samples])\n",
    "    def _f(img,bbox,lbl):\n",
    "        bbox = torch.cat([bbox,bbox.new_zeros(max_len-bbox.shape[0], 4)])\n",
    "        #lbl  = torch.cat([lbl, lbl .new_zeros(max_len-lbl .shape[0], int)+pad_idx])\n",
    "        #在无目标也就是lbl为[]的情况下，lbl  = torch.cat([lbl, lbl .new_zeros(max_len-lbl .shape[0])+pad_idx])\n",
    "        #上面的代码即使指定了dtype=torch.int得到的仍然是浮点数。会导致后面的报错不是索引\n",
    "        if lbl.shape[0] != 0:\n",
    "            lbl  = torch.cat([lbl, lbl .new_zeros(max_len-lbl .shape[0])+pad_idx])\n",
    "        else:\n",
    "            lbl = lbl.new_zeros(max_len, dtype = torch.int) + pad_idx\n",
    "\n",
    "        \n",
    "        return img,bbox,lbl\n",
    "    return [_f(*s) for s in samples]\n",
    "\n",
    "BBoxBlock = TransformBlock(type_tfms=TensorBBox.create, item_tfms=PointScaler, dls_kwargs = {'before_batch': bb_pad_intlbl})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取BBox和label  \n",
    "两个是分开进行的。并且BBox的顺序改成了先x后y，使用v1版的fastai的数据集的时候需要转换顺序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "pat_coord = re.compile(r'\\d+')\n",
    "pat_clas = re.compile(r'\\w+')\n",
    "pat_imgName = re.compile(r'(\\w+/\\d+\\.png)$')\n",
    "pat_imgName = re.compile(r'(\\w+/\\d+\\.jpg)$')\n",
    "def get_label_from_df(fn, df, pat_imgName, box_col, cat_col):    \n",
    "    fn = str(fn)\n",
    "    pat_cat = re.compile(r'\\w+')\n",
    "    \n",
    "    fn = pat_imgName.findall(str(fn))[0]\n",
    "    cats = df.loc[fn,cat_col]\n",
    "    cats = pat_clas.findall(cats)\n",
    "    \n",
    "    return cats\n",
    "\n",
    "def get_boxes_from_df(fn, df, pat_imgName, box_col, cat_col):\n",
    "    fn = str(fn)\n",
    "    pat_num = re.compile(r'\\d+')\n",
    "    pat_cat = re.compile(r'\\w+')\n",
    "    fn = pat_imgName.findall(str(fn))[0]\n",
    "    #print('dbg1', fn)\n",
    "    \n",
    "    boxes = df.loc[fn,box_col]\n",
    "    boxes = pat_num.findall(boxes)\n",
    "    #boxes = list(map(np.long, boxes))\n",
    "    boxes = list(map(np.int32, boxes))\n",
    "    boxes = np.array(boxes).reshape(-1,4)\n",
    "    \n",
    "    #fastai2里面bbox的顺序改成了xy的顺序。现在用的这个数据集还是v1里面的yx的顺序。这里调整一下\n",
    "    boxes = boxes[...,[1, 0, 3, 2]]\n",
    "    boxes = boxes.tolist()\n",
    "    \n",
    "    cats = df.loc[fn,cat_col]\n",
    "    cats = pat_clas.findall(cats)\n",
    "    #print('dbg2', fn, boxes, cats)\n",
    "    assert len(boxes)==len(cats), 'length of bounding boxes and categories not equeal.'\n",
    "    \n",
    "    #print('dbg_boxes:', boxes)    \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成DataBlock\n",
    "作用相当于之前的DataBunch  \n",
    "item_tfms=Resize(128) 作用类似v1里面的after_open，可以对图片进行一些处理，但是这个处理无法作用在y上,如果需要改变图片尺寸连带y一起改变，应该在aug_transforms里面指定size参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_db():\n",
    "    get_y1 = partial(get_boxes_from_df, df=df, pat_imgName=pat_imgName, box_col='box', cat_col='cls')\n",
    "    get_y2 = partial(get_label_from_df, df=df, pat_imgName=pat_imgName, box_col='box', cat_col='cls')\n",
    "    \n",
    "    syms = DataBlock(blocks=(ImageBlock, BBoxBlock, BBoxLblBlock),\n",
    "                     get_items=get_image_files,\n",
    "                     splitter=RandomSplitter(),\n",
    "                     get_y=[get_y1, get_y2],\n",
    "                     #item_tfms=Resize(128),\n",
    "                     #batch_tfms=aug_transforms(size=(128,128)),\n",
    "                     n_inp=1)\n",
    "    return syms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#添加的额外的metric项目。\n",
    "#在每一个batch结束的时候会接收到当前valid数据的pred和y\n",
    "#这个没法在epoch完毕的时候\n",
    "def ext_met(pred, yb0, yb1):\n",
    "    #import pdb;pdb.set_trace()\n",
    "    #rint('mymet',  val, kwargs)\n",
    "    \n",
    "    return 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#具体针对多余的验证集进行计算，用在ExtValidCal_met\n",
    "#使用者在这里进行计算\n",
    "def ext_valid_cal(learn, ext_valids):\n",
    "    return 3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#具体针对多余的多个验证集进行计算，用在ExtValidCal_cb\n",
    "#ext_valids是验证集的list\n",
    "#返回值必须是同样长度的list\n",
    "#使用者在这里进行计算\n",
    "def ext_multi_valid_cal(learn, ext_valids):\n",
    "    assert isinstance(ext_valids, list)\n",
    "    ret = []\n",
    "    for i in range(len(ext_valids)):\n",
    "        ret += [(i + 1) * 3.14]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtValidCal_cb(TrainEvalCallback):\n",
    "    '''\n",
    "    在after_validate阶段直接修改learn.recorder.log的内容。\n",
    "    可以添加多个自定义的字段\n",
    "    ''' \n",
    "    run_before = ProgressCallback\n",
    "    #新加的列的位置。默认前面是epoch，train_loss，valid_loss\n",
    "    #如果不一样这里要修改\n",
    "    POS = 3\n",
    "    def __init__(self, ext_valids = [], ext_titles = []\n",
    "                 , ext_cal_func = ext_multi_valid_cal\n",
    "                 , flag = 'callback__after_validate'):\n",
    "        self.ext_cal_func = ext_cal_func\n",
    "        self.flag = flag\n",
    "        self.ext_valids = ext_valids\n",
    "        self.ext_titles = ext_titles\n",
    "        assert len(ext_valids) > 0\n",
    "        assert len(ext_titles) == 0 or len(ext_titles) == len(ext_valids)\n",
    "        if len(ext_titles) == 0:\n",
    "            for i in range(len(ext_valids)):\n",
    "                self.ext_titles += ['ext_valid_%d' % (i + 1)]\n",
    "    \n",
    "    def before_fit(self, *args):\n",
    "        self.learn.recorder.metric_names  = \\\n",
    "            self.learn.recorder.metric_names[:self.POS] + \\\n",
    "            self.ext_titles + \\\n",
    "            self.learn.recorder.metric_names[self.POS:]\n",
    "                    \n",
    "            \n",
    "    def after_validate(self, *args):\n",
    "        r = self.ext_cal_func(self.learn, self.ext_valids)\n",
    "        self.learn.recorder.log = self.learn.recorder.log[:self.POS] \\\n",
    "            + r + self.learn.recorder.log[self.POS:]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtValidCal_met(TrainEvalCallback):\n",
    "    '''\n",
    "    添加自定义验证的位置：\n",
    "    1、在after_validate，ExtValidCal在Recorder之后运行(默认顺序)，\n",
    "        因为这时recorder.log还没有包含验证结果。为了能够修改题头，\n",
    "        需要指定：\n",
    "        self.run_before = ProgressCallback\n",
    "        也就是在Recorder之后ProgressCallback之前。\n",
    "        \n",
    "    2、也可以放在after_epoch，jupyter上更新训练结果的动作在Recorder的\n",
    "        after_epoch阶段添加自己的计算结果应该在这之前，所以需要指定\n",
    "        run_before=Recorder。\n",
    "        但是这种方式没法修改notebook显示结果的表格的题头（也就是\n",
    "        learn.recorder.metric_names）。\n",
    "        在创建learner的时候用metric=[xx]的方式指定内容的时候只能用一个\n",
    "        空函数作为题头的名字(在getattr获取'func'的时候返回的函数，函数\n",
    "        的名字作为题头出现)\n",
    "        \n",
    "    3、其余位置会因为在after_batch阶段对每个在Learner创建的时候指定\n",
    "        的metric条目调用的返回值覆盖，并且是每个batch都会调用。\n",
    "    '''   \n",
    "    def __init__(self, ext_cal_func = ext_valid_cal, ext_valids = None\n",
    "                 , ext_title = None, flag = 'metric__after_validate'):        \n",
    "        assert flag in ['metric__after_validate', 'metric__after_epoch'] \\\n",
    "                        , '无效flag:' + flag\n",
    "        self.ext_cal_func = ext_cal_func\n",
    "        self.flag = flag\n",
    "        self.ext_valids = ext_valids\n",
    "        if ext_title != None:\n",
    "            assert isinstance(ext_title, str), 'title必须是字符串'\n",
    "        #如果没有指定就用ext_valid\n",
    "        self.ext_title = ext_title if ext_title is not None else self.ext_valid.__name__\n",
    "        self.attr_called = False\n",
    "        \n",
    "        if flag == 'metric__after_epoch':\n",
    "            self.run_before = Recorder\n",
    "            assert ext_title is None, '无法修改title'\n",
    "        else:\n",
    "            self.run_before = ProgressCallback\n",
    "            \n",
    "    def __getattr__(self, k):\n",
    "        if k not in ['toward_end', 'run_before', 'run_after']:\n",
    "            print('getattr', k)\n",
    "        if 'func' == k: #fastai/learner.py(371)name()获取名字\n",
    "            self.attr_called = True\n",
    "            return self.ext_valid\n",
    "        return None\n",
    "            \n",
    "    def __call__(self, p2, *args):\n",
    "        #新加的列的位置。默认前面是epoch，train_loss，valid_loss\n",
    "        #如果不一样这里要修改\n",
    "        POS = 3\n",
    "        if isinstance(p2, str):\n",
    "            #print(p2)\n",
    "            if p2 == 'after_epoch' and self.flag == 'metric__after_epoch':\n",
    "                assert str(self.run_before) == str(Recorder), '必须指定run_before=Recorder'                \n",
    "                self.learn.recorder.log[POS] = self.ext_valid()\n",
    "                \n",
    "            if p2 == 'after_validate' and self.flag == 'metric__after_validate':\n",
    "                assert str(self.run_before) == str(ProgressCallback), '必须指定run_before=ProgressCallback'\n",
    "                self.learn.recorder.log[POS] = self.ext_valid()\n",
    "                    \n",
    "            #metric__after_validate的方式才能修改题头\n",
    "            if p2 == 'before_fit':\n",
    "                if self.flag == 'metric__after_validate':\n",
    "                    self.learn.recorder.metric_names[POS] = self.ext_title\n",
    "                elif self.flag == 'callback__after_validate':\n",
    "                    self.learn.recorder.metric_names  = self.learn.recorder.metric_names[:POS] \\\n",
    "                     + [self.ext_title] + self.learn.recorder.metric_names[POS:]\n",
    "                    \n",
    "            if p2 == 'before_epoch':\n",
    "                assert self.attr_called, '需要在创建learner的时候用metric参数指定'\n",
    "                \n",
    "            return 'fake_ret'\n",
    "        else:\n",
    "            #这里是每个batch之后对metrics立面每个项目的调用\n",
    "            #和ext_met的参数一致\n",
    "            pass\n",
    "        #没调用的话和一个单独的函数(ext_met)效果是一样的\n",
    "        assert self.learn is not None, '需要调用learn.add_cb'\n",
    "        return -1\n",
    "    \n",
    "    def ext_valid(self):\n",
    "        #return 'ext_valids_ret'\n",
    "        return self.ext_cal_func(self.learn, self.ext_valids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = '/home/dev/jupyter/detect_symbol/data/ds_20200429/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = src_path + 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(src_path + 'gends.csv',index_col=0)\n",
    "df = df.set_index('image')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syms = get_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在docker中如果没有设置-shm-size，不设置num_workers=0会使用_MultiProcessingDataLoaderIter，导致错误： \n",
    "Unable to write to file </torch_18692_1954506624>\n",
    "https://discuss.pytorch.org/t/unable-to-write-to-file-torch-18692-1954506624/9990\n",
    "\n",
    "在fastai v1中对应的错误是内存溢出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dls = syms.dataloaders(path, bs = 16, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dls.show_batch(max_n = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#syms.summary(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dts = syms.datasets(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc['images/02364.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型和训练-符号检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_ssd_detsym.get_resnet34_1ssd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvs,_,_,avs,_,_ = anchors_loss_metrics_detsym.get_ga666()\n",
    "gaf = anchors_loss_metrics_detsym.GridAnchor_Funcs(gvs,avs,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(anchors_loss_metrics_detsym.yolo_L, gaf=gaf, conf_th=1, clas_weights=None, lambda_nconf=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = cnn_learner(dls, model, pretrained=False)\n",
    "learn = Learner(dls, model, loss_func = loss_func, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 添加辅助寻来你的callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = CSVLogger('logger.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.add_cb(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SaveModelCallback\n",
    "v1中的name参数名换成了fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "autoSave = SaveModelCallback(monitor='valid_loss',mode='min',every='improvement',fname=f'run_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.add_cb(autoSave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorBoardCallback  \n",
    "v2中自带了这个类，不需要自己创建。\n",
    "\n",
    "log_preds参数表示是否记录预测结果，目前因为网络输出的预测结果不是和数据集的格式相同,导致在log_preds的过程中出现异常。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "异常情况：  \n",
    "b_out是由网络输出得到的结构(TensorImage,Tensor(bs,ac,2),Tensor(bs,ac,1),Tensor(bs,ac,17),Tensor(bs,ac,2))(其中ac是anchors数量)，被当作和数据集一致的结构(TensorImage, TensorBBox, TensorMultiCategory)处理。  \n",
    "/root/miniconda3/envs/fastai-v2/lib/python3.8/site-packages/fastai/data/core.py(107)show_results()=>\n",
    "x1,y1,outs = self.show_batch(b_out, max_n=max_n, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbcb = TensorBoardCallback(log_preds = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.add_cb(tbcb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单独验证集的计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback的方式增加多余的字段  \n",
    "这是最合适的实现方式，可以添加多列，列名可以自定义，在必要的时候才进行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evc = ExtValidCal_cb(ext_valids = [1,2], ext_titles = ['一个', '两个'])\n",
    "learn = Learner(dls, model, loss_func = loss_func, device = device)\n",
    "learn.add_cb(evc)\n",
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metric添加多余的字段  \n",
    "每个batch之后都会被调用到，会造成重复计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func = loss_func, device = device, metrics=[ext_met])\n",
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metric添加多余字段，另一种方式，可以修改字段题头  \n",
    "虽然没有每个batch之后都有的重复计算，但是只能添加一个字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#evc = ExtValidCal_met(flag = 'metric__after_epoch')#这种方式没法修改题头\n",
    "evc = ExtValidCal_met(ext_title = 'mytitle')\n",
    "#learn = Learner(dls, model, loss_func = loss_func, device = device)\n",
    "learn = Learner(dls, model, loss_func = loss_func, device = device, metrics=[evc])\n",
    "learn.add_cb(evc)\n",
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用病树检测的模型试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_ssd_sicktree.get_resnet18_1ssd(num_classes = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('../sick_tree_detection/models/pretrained_res18_1ssd_detsym17clas.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../sick_tree_detection/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaf = anchors_loss_metrics_sicktree.GridAnchor_Funcs(fig_hw = (776,776)\n",
    "                         , grids = [(49,49)]\n",
    "                         , device = device)\n",
    "gvs, avs = gaf.gvs, gaf.avs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_cnts = [11191, 712, 1362, 224, 8710, 1212, 1139, 8686, 857, 2176, 6175, 1869, 14794, 1435, 13628, 9618, 1462]\n",
    "weights = anchors_loss_metrics_detsym.get_clasWeights(clas_cnts,10)\n",
    "weights = tensor(weights).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(anchors_loss_metrics_sicktree.yolo_L, gaf=gaf, conf_th=1, clas_weights=None, lambda_nconf=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func = loss_func, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbg():\n",
    "    import pdb;pdb.set_trace();\n",
    "    dls = syms.dataloaders(path, bs = 16, num_workers = 0)\n",
    "#dbg()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossfunc_decodes(preds):\n",
    "    import pdb;pdb.set_trace()\n",
    "\n",
    "loss_func.decodes = lossfunc_decodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbg():\n",
    "    import pdb;pdb.set_trace();\n",
    "    learn.fit(1)\n",
    "#dbg()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb1 = torch.rand(2, 2)\n",
    "bb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2 = torch.rand(2, 2)\n",
    "bb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([bb1, bb2], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = torch.rand(16, 64601, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbb = TensorBBox(0)\n",
    "dir(tbb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
